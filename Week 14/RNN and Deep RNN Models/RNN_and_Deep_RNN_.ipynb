{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YGuzDQDxa2JZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DIFldc6Za8IA"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "data = pd.read_csv('/content/AirQualityUCI.csv', sep=';', decimal=',')\n",
        "data = data.dropna(subset=['CO(GT)'])  # Drop rows with missing target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7VOByp2Wa-SL"
      },
      "outputs": [],
      "source": [
        "# Select features and target\n",
        "features = data.iloc[:, :-2].select_dtypes(include=[np.number]).fillna(0).values\n",
        "target = data['CO(GT)'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hzGitHTIbA3y"
      },
      "outputs": [],
      "source": [
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cNGmXMtDhTaq"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "class AirQualityDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = AirQualityDataset(X_train, y_train)\n",
        "test_dataset = AirQualityDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L-e1U70vhULV"
      },
      "outputs": [],
      "source": [
        "# Define RNN model\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, pooling):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.pooling = pooling\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        if self.pooling == \"max\":\n",
        "            out, _ = torch.max(out, dim=1)\n",
        "        elif self.pooling == \"avg\":\n",
        "            out = torch.mean(out, dim=1)\n",
        "        out = self.fc(out)\n",
        "        return out.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation function\n",
        "def train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, scheduler=None, early_stopper=None, epochs=100):\n",
        "    epoch_list = []\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch.unsqueeze(1))\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in test_loader:\n",
        "                y_pred = model(X_batch.unsqueeze(1))\n",
        "                loss = criterion(y_pred, y_batch)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(test_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        epoch_list.append(epoch + 1)\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        if early_stopper and early_stopper.step(val_loss):\n",
        "            break\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return epoch_list, train_losses, val_losses"
      ],
      "metadata": {
        "id": "OybwaEay4Nlo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment configurations\n",
        "hidden_sizes = [10, 50, 100]\n",
        "pooling_methods = [\"max\", \"avg\"]\n",
        "optimizers = {\"SGD\": optim.SGD, \"RMSProp\": optim.RMSprop, \"Adam\": optim.Adam}\n",
        "epochs_list = [5, 50, 100, 250, 350]"
      ],
      "metadata": {
        "id": "TvLOXWjm4OY9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden size experiment\n",
        "hidden_size_results = []\n",
        "for hidden_size in hidden_sizes:\n",
        "    print(f\"Testing hidden_size={hidden_size}\")\n",
        "    model = RNNModel(input_size=X_train.shape[1], hidden_size=hidden_size, num_layers=1, pooling=\"avg\")\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
        "\n",
        "    epoch_list, train_losses, val_losses = train_and_evaluate(\n",
        "        model, optimizer, criterion, train_loader, test_loader, scheduler=scheduler, epochs=50\n",
        "    )\n",
        "    hidden_size_results.append({\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"epoch_list\": epoch_list,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-CB7np14QSI",
        "outputId": "d7ee849a-b3b7-448c-9498-7fbe81e1b69e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing hidden_size=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 6404.9417, Val Loss: 5354.5866\n",
            "Epoch 2/50, Train Loss: 4838.5961, Val Loss: 4039.4716\n",
            "Epoch 3/50, Train Loss: 3628.0711, Val Loss: 3002.8350\n",
            "Epoch 4/50, Train Loss: 2676.6573, Val Loss: 2192.0042\n",
            "Epoch 5/50, Train Loss: 1930.5843, Val Loss: 1558.5019\n",
            "Epoch 6/50, Train Loss: 1358.3764, Val Loss: 1080.7900\n",
            "Epoch 7/50, Train Loss: 928.8834, Val Loss: 728.3989\n",
            "Epoch 8/50, Train Loss: 616.5292, Val Loss: 475.6216\n",
            "Epoch 9/50, Train Loss: 397.8060, Val Loss: 303.1996\n",
            "Epoch 10/50, Train Loss: 251.9330, Val Loss: 189.6484\n",
            "Epoch 11/50, Train Loss: 157.9030, Val Loss: 120.3522\n",
            "Epoch 12/50, Train Loss: 101.9843, Val Loss: 80.3320\n",
            "Epoch 13/50, Train Loss: 70.7303, Val Loss: 58.1701\n",
            "Epoch 14/50, Train Loss: 54.7793, Val Loss: 49.1788\n",
            "Epoch 15/50, Train Loss: 46.7182, Val Loss: 42.4833\n",
            "Epoch 16/50, Train Loss: 43.0471, Val Loss: 39.9090\n",
            "Epoch 17/50, Train Loss: 41.1366, Val Loss: 38.5858\n",
            "Epoch 18/50, Train Loss: 39.7697, Val Loss: 37.6949\n",
            "Epoch 19/50, Train Loss: 38.8388, Val Loss: 36.3158\n",
            "Epoch 20/50, Train Loss: 37.4189, Val Loss: 35.1822\n",
            "Epoch 21/50, Train Loss: 36.2317, Val Loss: 34.1410\n",
            "Epoch 22/50, Train Loss: 35.0594, Val Loss: 32.8959\n",
            "Epoch 23/50, Train Loss: 33.5421, Val Loss: 31.2863\n",
            "Epoch 24/50, Train Loss: 32.0301, Val Loss: 29.8616\n",
            "Epoch 25/50, Train Loss: 30.4449, Val Loss: 28.4262\n",
            "Epoch 26/50, Train Loss: 28.9296, Val Loss: 26.8090\n",
            "Epoch 27/50, Train Loss: 27.2476, Val Loss: 25.2414\n",
            "Epoch 28/50, Train Loss: 25.4906, Val Loss: 23.4347\n",
            "Epoch 29/50, Train Loss: 23.5406, Val Loss: 21.4589\n",
            "Epoch 30/50, Train Loss: 21.8023, Val Loss: 19.8794\n",
            "Epoch 31/50, Train Loss: 20.6363, Val Loss: 20.8787\n",
            "Epoch 32/50, Train Loss: 20.6187, Val Loss: 18.9148\n",
            "Epoch 33/50, Train Loss: 18.9401, Val Loss: 17.3163\n",
            "Epoch 34/50, Train Loss: 17.3345, Val Loss: 15.6306\n",
            "Epoch 35/50, Train Loss: 15.6979, Val Loss: 13.9812\n",
            "Epoch 36/50, Train Loss: 13.5968, Val Loss: 12.1743\n",
            "Epoch 37/50, Train Loss: 11.6362, Val Loss: 10.0228\n",
            "Epoch 38/50, Train Loss: 9.5786, Val Loss: 8.1241\n",
            "Epoch 39/50, Train Loss: 7.8372, Val Loss: 6.5519\n",
            "Epoch 40/50, Train Loss: 6.6292, Val Loss: 8.5801\n",
            "Epoch 41/50, Train Loss: 5.8977, Val Loss: 4.2978\n",
            "Epoch 42/50, Train Loss: 3.9542, Val Loss: 3.2380\n",
            "Epoch 43/50, Train Loss: 3.3550, Val Loss: 2.4319\n",
            "Epoch 44/50, Train Loss: 2.2736, Val Loss: 1.8524\n",
            "Epoch 45/50, Train Loss: 1.6709, Val Loss: 1.2752\n",
            "Epoch 46/50, Train Loss: 1.6083, Val Loss: 3.2399\n",
            "Epoch 47/50, Train Loss: 1.0550, Val Loss: 0.6317\n",
            "Epoch 48/50, Train Loss: 0.6124, Val Loss: 0.4489\n",
            "Epoch 49/50, Train Loss: 0.9605, Val Loss: 0.2566\n",
            "Epoch 50/50, Train Loss: 0.2353, Val Loss: 0.1557\n",
            "Testing hidden_size=50\n",
            "Epoch 1/50, Train Loss: 3877.3986, Val Loss: 1454.3392\n",
            "Epoch 2/50, Train Loss: 670.4762, Val Loss: 183.8535\n",
            "Epoch 3/50, Train Loss: 70.9291, Val Loss: 15.5529\n",
            "Epoch 4/50, Train Loss: 8.7297, Val Loss: 4.2185\n",
            "Epoch 5/50, Train Loss: 4.2792, Val Loss: 3.8150\n",
            "Epoch 6/50, Train Loss: 4.1047, Val Loss: 3.7785\n",
            "Epoch 7/50, Train Loss: 3.8663, Val Loss: 3.5085\n",
            "Epoch 8/50, Train Loss: 3.8398, Val Loss: 3.2795\n",
            "Epoch 9/50, Train Loss: 3.9154, Val Loss: 3.4010\n",
            "Epoch 10/50, Train Loss: 3.3482, Val Loss: 2.9844\n",
            "Epoch 11/50, Train Loss: 3.1021, Val Loss: 2.8388\n",
            "Epoch 12/50, Train Loss: 2.8153, Val Loss: 2.5287\n",
            "Epoch 13/50, Train Loss: 2.7817, Val Loss: 2.3961\n",
            "Epoch 14/50, Train Loss: 2.4263, Val Loss: 2.1121\n",
            "Epoch 15/50, Train Loss: 2.1301, Val Loss: 1.9133\n",
            "Epoch 16/50, Train Loss: 1.9762, Val Loss: 1.5379\n",
            "Epoch 17/50, Train Loss: 1.4827, Val Loss: 1.1301\n",
            "Epoch 18/50, Train Loss: 0.8787, Val Loss: 0.6853\n",
            "Epoch 19/50, Train Loss: 0.7044, Val Loss: 0.6114\n",
            "Epoch 20/50, Train Loss: 0.5298, Val Loss: 0.3935\n",
            "Epoch 21/50, Train Loss: 0.5590, Val Loss: 0.2513\n",
            "Epoch 22/50, Train Loss: 0.2462, Val Loss: 0.1593\n",
            "Epoch 23/50, Train Loss: 0.1936, Val Loss: 0.1161\n",
            "Epoch 24/50, Train Loss: 0.1221, Val Loss: 0.1758\n",
            "Epoch 25/50, Train Loss: 0.3980, Val Loss: 0.0653\n",
            "Epoch 26/50, Train Loss: 0.0771, Val Loss: 0.1207\n",
            "Epoch 27/50, Train Loss: 0.0945, Val Loss: 0.0655\n",
            "Epoch 28/50, Train Loss: 0.1429, Val Loss: 0.2510\n",
            "Epoch 29/50, Train Loss: 0.0957, Val Loss: 0.1094\n",
            "Epoch 30/50, Train Loss: 0.1461, Val Loss: 0.0930\n",
            "Epoch 31/50, Train Loss: 0.0990, Val Loss: 0.1538\n",
            "Epoch 32/50, Train Loss: 0.0367, Val Loss: 0.0278\n",
            "Epoch 33/50, Train Loss: 0.0283, Val Loss: 0.0261\n",
            "Epoch 34/50, Train Loss: 0.0259, Val Loss: 0.0284\n",
            "Epoch 35/50, Train Loss: 0.0280, Val Loss: 0.0244\n",
            "Epoch 36/50, Train Loss: 0.0263, Val Loss: 0.0243\n",
            "Epoch 37/50, Train Loss: 0.0261, Val Loss: 0.0213\n",
            "Epoch 38/50, Train Loss: 0.0239, Val Loss: 0.0201\n",
            "Epoch 39/50, Train Loss: 0.0218, Val Loss: 0.0213\n",
            "Epoch 40/50, Train Loss: 0.0205, Val Loss: 0.0239\n",
            "Epoch 41/50, Train Loss: 0.0241, Val Loss: 0.0187\n",
            "Epoch 42/50, Train Loss: 0.0199, Val Loss: 0.0144\n",
            "Epoch 43/50, Train Loss: 0.0219, Val Loss: 0.0173\n",
            "Epoch 44/50, Train Loss: 0.0192, Val Loss: 0.0144\n",
            "Epoch 45/50, Train Loss: 0.0186, Val Loss: 0.0185\n",
            "Epoch 46/50, Train Loss: 0.0191, Val Loss: 0.0215\n",
            "Epoch 47/50, Train Loss: 0.0201, Val Loss: 0.0173\n",
            "Epoch 48/50, Train Loss: 0.0184, Val Loss: 0.0136\n",
            "Epoch 49/50, Train Loss: 0.0181, Val Loss: 0.0150\n",
            "Epoch 50/50, Train Loss: 0.0173, Val Loss: 0.0163\n",
            "Testing hidden_size=100\n",
            "Epoch 1/50, Train Loss: 2461.3360, Val Loss: 173.7441\n",
            "Epoch 2/50, Train Loss: 41.7397, Val Loss: 8.8299\n",
            "Epoch 3/50, Train Loss: 9.3883, Val Loss: 8.3450\n",
            "Epoch 4/50, Train Loss: 9.3493, Val Loss: 7.6681\n",
            "Epoch 5/50, Train Loss: 7.3007, Val Loss: 6.3681\n",
            "Epoch 6/50, Train Loss: 6.3506, Val Loss: 6.0345\n",
            "Epoch 7/50, Train Loss: 5.5550, Val Loss: 4.6867\n",
            "Epoch 8/50, Train Loss: 4.6001, Val Loss: 3.8932\n",
            "Epoch 9/50, Train Loss: 3.9029, Val Loss: 3.2681\n",
            "Epoch 10/50, Train Loss: 3.2588, Val Loss: 2.7943\n",
            "Epoch 11/50, Train Loss: 2.5848, Val Loss: 2.5862\n",
            "Epoch 12/50, Train Loss: 1.7580, Val Loss: 1.1880\n",
            "Epoch 13/50, Train Loss: 1.2533, Val Loss: 0.7205\n",
            "Epoch 14/50, Train Loss: 0.7715, Val Loss: 0.4847\n",
            "Epoch 15/50, Train Loss: 0.5401, Val Loss: 0.6069\n",
            "Epoch 16/50, Train Loss: 0.5610, Val Loss: 0.2130\n",
            "Epoch 17/50, Train Loss: 0.2953, Val Loss: 0.1478\n",
            "Epoch 18/50, Train Loss: 0.3253, Val Loss: 0.1448\n",
            "Epoch 19/50, Train Loss: 0.1752, Val Loss: 0.1186\n",
            "Epoch 20/50, Train Loss: 0.1666, Val Loss: 0.0985\n",
            "Epoch 21/50, Train Loss: 0.3006, Val Loss: 0.4500\n",
            "Epoch 22/50, Train Loss: 0.3697, Val Loss: 0.0884\n",
            "Epoch 23/50, Train Loss: 0.1798, Val Loss: 0.1582\n",
            "Epoch 24/50, Train Loss: 0.1913, Val Loss: 0.0963\n",
            "Epoch 25/50, Train Loss: 0.1377, Val Loss: 0.0746\n",
            "Epoch 26/50, Train Loss: 0.1066, Val Loss: 0.0687\n",
            "Epoch 27/50, Train Loss: 0.1159, Val Loss: 0.0863\n",
            "Epoch 28/50, Train Loss: 0.1618, Val Loss: 0.1004\n",
            "Epoch 29/50, Train Loss: 0.1063, Val Loss: 0.1776\n",
            "Epoch 30/50, Train Loss: 0.1486, Val Loss: 0.1983\n",
            "Epoch 31/50, Train Loss: 0.1663, Val Loss: 0.1271\n",
            "Epoch 32/50, Train Loss: 0.2003, Val Loss: 0.1233\n",
            "Epoch 33/50, Train Loss: 0.0383, Val Loss: 0.0318\n",
            "Epoch 34/50, Train Loss: 0.0294, Val Loss: 0.0302\n",
            "Epoch 35/50, Train Loss: 0.0290, Val Loss: 0.0281\n",
            "Epoch 36/50, Train Loss: 0.0275, Val Loss: 0.0314\n",
            "Epoch 37/50, Train Loss: 0.0264, Val Loss: 0.0293\n",
            "Epoch 38/50, Train Loss: 0.0264, Val Loss: 0.0302\n",
            "Epoch 39/50, Train Loss: 0.0269, Val Loss: 0.0275\n",
            "Epoch 40/50, Train Loss: 0.0262, Val Loss: 0.0236\n",
            "Epoch 41/50, Train Loss: 0.0253, Val Loss: 0.0284\n",
            "Epoch 42/50, Train Loss: 0.0251, Val Loss: 0.0237\n",
            "Epoch 43/50, Train Loss: 0.0243, Val Loss: 0.0240\n",
            "Epoch 44/50, Train Loss: 0.0231, Val Loss: 0.0264\n",
            "Epoch 45/50, Train Loss: 0.0245, Val Loss: 0.0234\n",
            "Epoch 46/50, Train Loss: 0.0259, Val Loss: 0.0237\n",
            "Epoch 47/50, Train Loss: 0.0228, Val Loss: 0.0276\n",
            "Epoch 48/50, Train Loss: 0.0246, Val Loss: 0.0200\n",
            "Epoch 49/50, Train Loss: 0.0255, Val Loss: 0.0268\n",
            "Epoch 50/50, Train Loss: 0.0232, Val Loss: 0.0299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling method experiment\n",
        "pooling_results = []\n",
        "for pooling in pooling_methods:\n",
        "    print(f\"Testing pooling method={pooling}\")\n",
        "    model = RNNModel(input_size=X_train.shape[1], hidden_size=50, num_layers=1, pooling=pooling)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
        "\n",
        "    epoch_list, train_losses, val_losses = train_and_evaluate(\n",
        "        model, optimizer, criterion, train_loader, test_loader, scheduler=scheduler, epochs=50\n",
        "    )\n",
        "    pooling_results.append({\n",
        "        \"pooling\": pooling,\n",
        "        \"epoch_list\": epoch_list,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaGlteJ34SSI",
        "outputId": "84400f46-f80a-4aa9-8559-dd28fb6a2a55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing pooling method=max\n",
            "Epoch 1/50, Train Loss: 3934.9736, Val Loss: 1530.3412\n",
            "Epoch 2/50, Train Loss: 704.3219, Val Loss: 197.4912\n",
            "Epoch 3/50, Train Loss: 79.0444, Val Loss: 20.2773\n",
            "Epoch 4/50, Train Loss: 12.5709, Val Loss: 10.1186\n",
            "Epoch 5/50, Train Loss: 8.5653, Val Loss: 7.8905\n",
            "Epoch 6/50, Train Loss: 8.1210, Val Loss: 7.2380\n",
            "Epoch 7/50, Train Loss: 7.4897, Val Loss: 6.9480\n",
            "Epoch 8/50, Train Loss: 7.0869, Val Loss: 6.6053\n",
            "Epoch 9/50, Train Loss: 6.7362, Val Loss: 6.0403\n",
            "Epoch 10/50, Train Loss: 6.0912, Val Loss: 5.5766\n",
            "Epoch 11/50, Train Loss: 5.5995, Val Loss: 5.0378\n",
            "Epoch 12/50, Train Loss: 5.3579, Val Loss: 4.5105\n",
            "Epoch 13/50, Train Loss: 4.4828, Val Loss: 4.0741\n",
            "Epoch 14/50, Train Loss: 3.7708, Val Loss: 3.1066\n",
            "Epoch 15/50, Train Loss: 2.8079, Val Loss: 2.2705\n",
            "Epoch 16/50, Train Loss: 2.1089, Val Loss: 1.7462\n",
            "Epoch 17/50, Train Loss: 1.6032, Val Loss: 1.3149\n",
            "Epoch 18/50, Train Loss: 1.1446, Val Loss: 0.9650\n",
            "Epoch 19/50, Train Loss: 0.9059, Val Loss: 0.5335\n",
            "Epoch 20/50, Train Loss: 0.4751, Val Loss: 0.3635\n",
            "Epoch 21/50, Train Loss: 0.4741, Val Loss: 0.2468\n",
            "Epoch 22/50, Train Loss: 0.2473, Val Loss: 0.2614\n",
            "Epoch 23/50, Train Loss: 0.1700, Val Loss: 0.1161\n",
            "Epoch 24/50, Train Loss: 0.1208, Val Loss: 0.0834\n",
            "Epoch 25/50, Train Loss: 0.1475, Val Loss: 0.1887\n",
            "Epoch 26/50, Train Loss: 0.0771, Val Loss: 0.0678\n",
            "Epoch 27/50, Train Loss: 0.0990, Val Loss: 0.0513\n",
            "Epoch 28/50, Train Loss: 0.1230, Val Loss: 0.1692\n",
            "Epoch 29/50, Train Loss: 0.0990, Val Loss: 0.0670\n",
            "Epoch 30/50, Train Loss: 0.0916, Val Loss: 0.2378\n",
            "Epoch 31/50, Train Loss: 0.2442, Val Loss: 0.3755\n",
            "Epoch 32/50, Train Loss: 0.1649, Val Loss: 0.1538\n",
            "Epoch 33/50, Train Loss: 0.1142, Val Loss: 0.1993\n",
            "Epoch 34/50, Train Loss: 0.0354, Val Loss: 0.0302\n",
            "Epoch 35/50, Train Loss: 0.0288, Val Loss: 0.0281\n",
            "Epoch 36/50, Train Loss: 0.0262, Val Loss: 0.0270\n",
            "Epoch 37/50, Train Loss: 0.0257, Val Loss: 0.0248\n",
            "Epoch 38/50, Train Loss: 0.0229, Val Loss: 0.0237\n",
            "Epoch 39/50, Train Loss: 0.0222, Val Loss: 0.0232\n",
            "Epoch 40/50, Train Loss: 0.0225, Val Loss: 0.0231\n",
            "Epoch 41/50, Train Loss: 0.0225, Val Loss: 0.0197\n",
            "Epoch 42/50, Train Loss: 0.0198, Val Loss: 0.0197\n",
            "Epoch 43/50, Train Loss: 0.0196, Val Loss: 0.0448\n",
            "Epoch 44/50, Train Loss: 0.0197, Val Loss: 0.0210\n",
            "Epoch 45/50, Train Loss: 0.0196, Val Loss: 0.0170\n",
            "Epoch 46/50, Train Loss: 0.0195, Val Loss: 0.0212\n",
            "Epoch 47/50, Train Loss: 0.0170, Val Loss: 0.0175\n",
            "Epoch 48/50, Train Loss: 0.0183, Val Loss: 0.0153\n",
            "Epoch 49/50, Train Loss: 0.0190, Val Loss: 0.0169\n",
            "Epoch 50/50, Train Loss: 0.0165, Val Loss: 0.0203\n",
            "Testing pooling method=avg\n",
            "Epoch 1/50, Train Loss: 4001.6633, Val Loss: 1532.5184\n",
            "Epoch 2/50, Train Loss: 716.1366, Val Loss: 211.7102\n",
            "Epoch 3/50, Train Loss: 89.6798, Val Loss: 30.2269\n",
            "Epoch 4/50, Train Loss: 22.4950, Val Loss: 18.1702\n",
            "Epoch 5/50, Train Loss: 17.9927, Val Loss: 16.3309\n",
            "Epoch 6/50, Train Loss: 16.8296, Val Loss: 15.4993\n",
            "Epoch 7/50, Train Loss: 15.6679, Val Loss: 14.7922\n",
            "Epoch 8/50, Train Loss: 14.7687, Val Loss: 13.1861\n",
            "Epoch 9/50, Train Loss: 13.4208, Val Loss: 12.0274\n",
            "Epoch 10/50, Train Loss: 12.0528, Val Loss: 10.8506\n",
            "Epoch 11/50, Train Loss: 10.7678, Val Loss: 9.4767\n",
            "Epoch 12/50, Train Loss: 9.3757, Val Loss: 8.2513\n",
            "Epoch 13/50, Train Loss: 8.2685, Val Loss: 7.0537\n",
            "Epoch 14/50, Train Loss: 6.6129, Val Loss: 5.4551\n",
            "Epoch 15/50, Train Loss: 4.9399, Val Loss: 3.9571\n",
            "Epoch 16/50, Train Loss: 3.5214, Val Loss: 2.7178\n",
            "Epoch 17/50, Train Loss: 2.5563, Val Loss: 1.9716\n",
            "Epoch 18/50, Train Loss: 1.7480, Val Loss: 1.3001\n",
            "Epoch 19/50, Train Loss: 1.1276, Val Loss: 0.9489\n",
            "Epoch 20/50, Train Loss: 0.8024, Val Loss: 0.6973\n",
            "Epoch 21/50, Train Loss: 0.6589, Val Loss: 0.3788\n",
            "Epoch 22/50, Train Loss: 0.3094, Val Loss: 0.2140\n",
            "Epoch 23/50, Train Loss: 0.2327, Val Loss: 0.1133\n",
            "Epoch 24/50, Train Loss: 0.1497, Val Loss: 0.0778\n",
            "Epoch 25/50, Train Loss: 0.0826, Val Loss: 0.3217\n",
            "Epoch 26/50, Train Loss: 0.1397, Val Loss: 0.0607\n",
            "Epoch 27/50, Train Loss: 0.0641, Val Loss: 0.0556\n",
            "Epoch 28/50, Train Loss: 0.1136, Val Loss: 0.0328\n",
            "Epoch 29/50, Train Loss: 0.0895, Val Loss: 0.0774\n",
            "Epoch 30/50, Train Loss: 0.0762, Val Loss: 0.0580\n",
            "Epoch 31/50, Train Loss: 0.0715, Val Loss: 0.0583\n",
            "Epoch 32/50, Train Loss: 0.0479, Val Loss: 0.0281\n",
            "Epoch 33/50, Train Loss: 0.0768, Val Loss: 0.0383\n",
            "Epoch 34/50, Train Loss: 0.0869, Val Loss: 0.0761\n",
            "Epoch 35/50, Train Loss: 0.0779, Val Loss: 0.0694\n",
            "Epoch 36/50, Train Loss: 0.0923, Val Loss: 0.0586\n",
            "Epoch 37/50, Train Loss: 0.0688, Val Loss: 0.1517\n",
            "Epoch 38/50, Train Loss: 0.1935, Val Loss: 0.1590\n",
            "Epoch 39/50, Train Loss: 0.0484, Val Loss: 0.0364\n",
            "Epoch 40/50, Train Loss: 0.0344, Val Loss: 0.0341\n",
            "Epoch 41/50, Train Loss: 0.0319, Val Loss: 0.0350\n",
            "Epoch 42/50, Train Loss: 0.0289, Val Loss: 0.0401\n",
            "Epoch 43/50, Train Loss: 0.0271, Val Loss: 0.0267\n",
            "Epoch 44/50, Train Loss: 0.0257, Val Loss: 0.0250\n",
            "Epoch 45/50, Train Loss: 0.0231, Val Loss: 0.0262\n",
            "Epoch 46/50, Train Loss: 0.0230, Val Loss: 0.0223\n",
            "Epoch 47/50, Train Loss: 0.0208, Val Loss: 0.0281\n",
            "Epoch 48/50, Train Loss: 0.0210, Val Loss: 0.0262\n",
            "Epoch 49/50, Train Loss: 0.0212, Val Loss: 0.0180\n",
            "Epoch 50/50, Train Loss: 0.0206, Val Loss: 0.0215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer experiment\n",
        "optimizer_results = []\n",
        "for opt_name, opt_class in optimizers.items():\n",
        "    print(f\"Testing optimizer={opt_name}\")\n",
        "    model = RNNModel(input_size=X_train.shape[1], hidden_size=50, num_layers=1, pooling=\"avg\")\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = opt_class(model.parameters(), lr=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
        "\n",
        "    epoch_list, train_losses, val_losses = train_and_evaluate(\n",
        "        model, optimizer, criterion, train_loader, test_loader, scheduler=scheduler, epochs=50\n",
        "    )\n",
        "    optimizer_results.append({\n",
        "        \"optimizer\": opt_name,\n",
        "        \"epoch_list\": epoch_list,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAtnRnRA4UVr",
        "outputId": "ac4a6e3a-e1fb-4b1b-a7bf-bf45bd779c54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing optimizer=SGD\n",
            "Epoch 1/50, Train Loss: 382.1930, Val Loss: 102.3539\n",
            "Epoch 2/50, Train Loss: 85.3499, Val Loss: 62.7287\n",
            "Epoch 3/50, Train Loss: 59.1559, Val Loss: 45.5655\n",
            "Epoch 4/50, Train Loss: 41.3499, Val Loss: 34.6714\n",
            "Epoch 5/50, Train Loss: 65.0658, Val Loss: 59.3797\n",
            "Epoch 6/50, Train Loss: 53.7081, Val Loss: 45.5061\n",
            "Epoch 7/50, Train Loss: 43.2222, Val Loss: 36.7015\n",
            "Epoch 8/50, Train Loss: 35.1952, Val Loss: 30.7316\n",
            "Epoch 9/50, Train Loss: 28.4441, Val Loss: 24.7603\n",
            "Epoch 10/50, Train Loss: 23.0567, Val Loss: 19.9314\n",
            "Epoch 11/50, Train Loss: 66.3637, Val Loss: 66.8327\n",
            "Epoch 12/50, Train Loss: 81.0056, Val Loss: 60.4122\n",
            "Epoch 13/50, Train Loss: 77.0846, Val Loss: 55.3441\n",
            "Epoch 14/50, Train Loss: 153.2407, Val Loss: 152.9265\n",
            "Epoch 15/50, Train Loss: 161.5361, Val Loss: 146.2602\n",
            "Epoch 16/50, Train Loss: 151.3548, Val Loss: 143.1047\n",
            "Epoch 17/50, Train Loss: 147.7077, Val Loss: 142.5555\n",
            "Epoch 18/50, Train Loss: 147.2846, Val Loss: 142.2111\n",
            "Epoch 19/50, Train Loss: 147.1318, Val Loss: 142.1326\n",
            "Epoch 20/50, Train Loss: 145.7898, Val Loss: 135.0635\n",
            "Epoch 21/50, Train Loss: 139.0363, Val Loss: 133.4174\n",
            "Epoch 22/50, Train Loss: 136.8921, Val Loss: 131.7577\n",
            "Epoch 23/50, Train Loss: 135.6420, Val Loss: 131.6037\n",
            "Epoch 24/50, Train Loss: 135.4607, Val Loss: 131.4454\n",
            "Epoch 25/50, Train Loss: 135.3043, Val Loss: 131.2957\n",
            "Epoch 26/50, Train Loss: 135.1544, Val Loss: 131.1415\n",
            "Epoch 27/50, Train Loss: 134.9695, Val Loss: 130.9918\n",
            "Epoch 28/50, Train Loss: 134.8131, Val Loss: 130.8383\n",
            "Epoch 29/50, Train Loss: 134.6859, Val Loss: 130.8232\n",
            "Epoch 30/50, Train Loss: 135.0946, Val Loss: 130.8081\n",
            "Epoch 31/50, Train Loss: 134.6497, Val Loss: 130.7929\n",
            "Epoch 32/50, Train Loss: 134.6339, Val Loss: 130.7778\n",
            "Epoch 33/50, Train Loss: 134.6246, Val Loss: 130.7627\n",
            "Epoch 34/50, Train Loss: 134.6025, Val Loss: 130.7475\n",
            "Epoch 35/50, Train Loss: 134.5891, Val Loss: 130.7460\n",
            "Epoch 36/50, Train Loss: 134.5875, Val Loss: 130.7445\n",
            "Epoch 37/50, Train Loss: 134.5862, Val Loss: 130.7430\n",
            "Epoch 38/50, Train Loss: 134.5843, Val Loss: 130.7415\n",
            "Epoch 39/50, Train Loss: 134.5983, Val Loss: 130.7400\n",
            "Epoch 40/50, Train Loss: 134.5862, Val Loss: 130.7385\n",
            "Epoch 41/50, Train Loss: 134.5798, Val Loss: 130.7384\n",
            "Epoch 42/50, Train Loss: 134.5797, Val Loss: 130.7383\n",
            "Epoch 43/50, Train Loss: 134.5839, Val Loss: 130.7381\n",
            "Epoch 44/50, Train Loss: 134.5916, Val Loss: 130.7380\n",
            "Epoch 45/50, Train Loss: 134.5793, Val Loss: 130.7379\n",
            "Epoch 46/50, Train Loss: 134.5793, Val Loss: 130.7378\n",
            "Epoch 47/50, Train Loss: 134.5790, Val Loss: 130.7377\n",
            "Epoch 48/50, Train Loss: 134.5881, Val Loss: 130.7378\n",
            "Epoch 49/50, Train Loss: 135.0124, Val Loss: 130.7378\n",
            "Epoch 50/50, Train Loss: 134.5846, Val Loss: 130.7378\n",
            "Testing optimizer=RMSProp\n",
            "Epoch 1/50, Train Loss: 2047.5131, Val Loss: 449.8329\n",
            "Epoch 2/50, Train Loss: 148.1318, Val Loss: 22.5088\n",
            "Epoch 3/50, Train Loss: 19.9126, Val Loss: 15.6534\n",
            "Epoch 4/50, Train Loss: 15.7278, Val Loss: 11.3769\n",
            "Epoch 5/50, Train Loss: 11.1957, Val Loss: 17.1481\n",
            "Epoch 6/50, Train Loss: 7.5724, Val Loss: 5.3616\n",
            "Epoch 7/50, Train Loss: 4.9120, Val Loss: 2.3721\n",
            "Epoch 8/50, Train Loss: 2.4692, Val Loss: 1.4358\n",
            "Epoch 9/50, Train Loss: 1.7830, Val Loss: 0.7148\n",
            "Epoch 10/50, Train Loss: 1.2078, Val Loss: 1.8488\n",
            "Epoch 11/50, Train Loss: 1.0027, Val Loss: 0.3113\n",
            "Epoch 12/50, Train Loss: 0.8731, Val Loss: 0.2111\n",
            "Epoch 13/50, Train Loss: 0.7415, Val Loss: 0.5278\n",
            "Epoch 14/50, Train Loss: 0.7260, Val Loss: 0.7201\n",
            "Epoch 15/50, Train Loss: 0.6489, Val Loss: 0.3203\n",
            "Epoch 16/50, Train Loss: 0.6417, Val Loss: 0.2147\n",
            "Epoch 17/50, Train Loss: 0.5996, Val Loss: 0.4329\n",
            "Epoch 18/50, Train Loss: 0.5570, Val Loss: 0.3574\n",
            "Epoch 19/50, Train Loss: 0.1659, Val Loss: 0.1500\n",
            "Epoch 20/50, Train Loss: 0.1335, Val Loss: 0.1292\n",
            "Epoch 21/50, Train Loss: 0.1201, Val Loss: 0.1144\n",
            "Epoch 22/50, Train Loss: 0.1101, Val Loss: 0.1097\n",
            "Epoch 23/50, Train Loss: 0.1038, Val Loss: 0.1007\n",
            "Epoch 24/50, Train Loss: 0.0970, Val Loss: 0.0990\n",
            "Epoch 25/50, Train Loss: 0.0923, Val Loss: 0.0869\n",
            "Epoch 26/50, Train Loss: 0.0874, Val Loss: 0.0816\n",
            "Epoch 27/50, Train Loss: 0.0804, Val Loss: 0.1136\n",
            "Epoch 28/50, Train Loss: 0.0785, Val Loss: 0.0804\n",
            "Epoch 29/50, Train Loss: 0.0757, Val Loss: 0.0678\n",
            "Epoch 30/50, Train Loss: 0.0721, Val Loss: 0.0711\n",
            "Epoch 31/50, Train Loss: 0.0678, Val Loss: 0.0606\n",
            "Epoch 32/50, Train Loss: 0.0660, Val Loss: 0.0645\n",
            "Epoch 33/50, Train Loss: 0.0639, Val Loss: 0.0545\n",
            "Epoch 34/50, Train Loss: 0.0617, Val Loss: 0.0513\n",
            "Epoch 35/50, Train Loss: 0.0557, Val Loss: 0.0478\n",
            "Epoch 36/50, Train Loss: 0.0554, Val Loss: 0.0697\n",
            "Epoch 37/50, Train Loss: 0.0535, Val Loss: 0.0728\n",
            "Epoch 38/50, Train Loss: 0.0517, Val Loss: 0.0410\n",
            "Epoch 39/50, Train Loss: 0.0512, Val Loss: 0.0394\n",
            "Epoch 40/50, Train Loss: 0.0477, Val Loss: 0.0406\n",
            "Epoch 41/50, Train Loss: 0.0463, Val Loss: 0.0403\n",
            "Epoch 42/50, Train Loss: 0.0465, Val Loss: 0.0338\n",
            "Epoch 43/50, Train Loss: 0.0439, Val Loss: 0.1232\n",
            "Epoch 44/50, Train Loss: 0.0443, Val Loss: 0.0435\n",
            "Epoch 45/50, Train Loss: 0.0427, Val Loss: 0.0433\n",
            "Epoch 46/50, Train Loss: 0.0409, Val Loss: 0.0390\n",
            "Epoch 47/50, Train Loss: 0.0420, Val Loss: 0.0302\n",
            "Epoch 48/50, Train Loss: 0.0372, Val Loss: 0.0372\n",
            "Epoch 49/50, Train Loss: 0.0384, Val Loss: 0.0440\n",
            "Epoch 50/50, Train Loss: 0.0388, Val Loss: 0.0313\n",
            "Testing optimizer=Adam\n",
            "Epoch 1/50, Train Loss: 3953.0982, Val Loss: 1516.4063\n",
            "Epoch 2/50, Train Loss: 701.8503, Val Loss: 192.6438\n",
            "Epoch 3/50, Train Loss: 76.3321, Val Loss: 17.1966\n",
            "Epoch 4/50, Train Loss: 8.2088, Val Loss: 4.2335\n",
            "Epoch 5/50, Train Loss: 4.4008, Val Loss: 4.4048\n",
            "Epoch 6/50, Train Loss: 4.1747, Val Loss: 3.7641\n",
            "Epoch 7/50, Train Loss: 3.8430, Val Loss: 3.4761\n",
            "Epoch 8/50, Train Loss: 3.7409, Val Loss: 3.2866\n",
            "Epoch 9/50, Train Loss: 3.4407, Val Loss: 3.1367\n",
            "Epoch 10/50, Train Loss: 3.2895, Val Loss: 3.2880\n",
            "Epoch 11/50, Train Loss: 3.5767, Val Loss: 3.3161\n",
            "Epoch 12/50, Train Loss: 2.7744, Val Loss: 2.5121\n",
            "Epoch 13/50, Train Loss: 2.5838, Val Loss: 2.3113\n",
            "Epoch 14/50, Train Loss: 2.3467, Val Loss: 2.1425\n",
            "Epoch 15/50, Train Loss: 2.0573, Val Loss: 1.8059\n",
            "Epoch 16/50, Train Loss: 1.6961, Val Loss: 1.3843\n",
            "Epoch 17/50, Train Loss: 1.2451, Val Loss: 1.1219\n",
            "Epoch 18/50, Train Loss: 0.8727, Val Loss: 0.6682\n",
            "Epoch 19/50, Train Loss: 0.6574, Val Loss: 0.5273\n",
            "Epoch 20/50, Train Loss: 0.6323, Val Loss: 0.3946\n",
            "Epoch 21/50, Train Loss: 0.3074, Val Loss: 0.2419\n",
            "Epoch 22/50, Train Loss: 0.2256, Val Loss: 0.1508\n",
            "Epoch 23/50, Train Loss: 0.1616, Val Loss: 0.1778\n",
            "Epoch 24/50, Train Loss: 0.1332, Val Loss: 0.2816\n",
            "Epoch 25/50, Train Loss: 0.2736, Val Loss: 0.0719\n",
            "Epoch 26/50, Train Loss: 0.1099, Val Loss: 0.0872\n",
            "Epoch 27/50, Train Loss: 0.0837, Val Loss: 0.0727\n",
            "Epoch 28/50, Train Loss: 0.0811, Val Loss: 0.0721\n",
            "Epoch 29/50, Train Loss: 0.0831, Val Loss: 0.0861\n",
            "Epoch 30/50, Train Loss: 0.0733, Val Loss: 0.0567\n",
            "Epoch 31/50, Train Loss: 0.1248, Val Loss: 0.0996\n",
            "Epoch 32/50, Train Loss: 0.1052, Val Loss: 0.0376\n",
            "Epoch 33/50, Train Loss: 0.0953, Val Loss: 0.0549\n",
            "Epoch 34/50, Train Loss: 0.2277, Val Loss: 0.1367\n",
            "Epoch 35/50, Train Loss: 0.0898, Val Loss: 0.0576\n",
            "Epoch 36/50, Train Loss: 0.1412, Val Loss: 0.3414\n",
            "Epoch 37/50, Train Loss: 0.1161, Val Loss: 0.1215\n",
            "Epoch 38/50, Train Loss: 0.1873, Val Loss: 0.2401\n",
            "Epoch 39/50, Train Loss: 0.0676, Val Loss: 0.0538\n",
            "Epoch 40/50, Train Loss: 0.0464, Val Loss: 0.0490\n",
            "Epoch 41/50, Train Loss: 0.0414, Val Loss: 0.0396\n",
            "Epoch 42/50, Train Loss: 0.0399, Val Loss: 0.0410\n",
            "Epoch 43/50, Train Loss: 0.0370, Val Loss: 0.0325\n",
            "Epoch 44/50, Train Loss: 0.0357, Val Loss: 0.0296\n",
            "Epoch 45/50, Train Loss: 0.0315, Val Loss: 0.0320\n",
            "Epoch 46/50, Train Loss: 0.0296, Val Loss: 0.0372\n",
            "Epoch 47/50, Train Loss: 0.0261, Val Loss: 0.0240\n",
            "Epoch 48/50, Train Loss: 0.0220, Val Loss: 0.0229\n",
            "Epoch 49/50, Train Loss: 0.0218, Val Loss: 0.0232\n",
            "Epoch 50/50, Train Loss: 0.0207, Val Loss: 0.0171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epoch experiment\n",
        "epoch_results = []\n",
        "for epochs in epochs_list:\n",
        "    print(f\"Testing epochs={epochs}\")\n",
        "    model = RNNModel(input_size=X_train.shape[1], hidden_size=50, num_layers=1, pooling=\"avg\")\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
        "\n",
        "    epoch_list, train_losses, val_losses = train_and_evaluate(\n",
        "        model, optimizer, criterion, train_loader, test_loader, scheduler=scheduler, epochs=epochs\n",
        "    )\n",
        "    epoch_results.append({\n",
        "        \"epochs\": epochs,\n",
        "        \"epoch_list\": epoch_list,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKMibddu4Wbb",
        "outputId": "be0e09ac-68fe-4147-8b54-1fc7fd410234"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing epochs=5\n",
            "Epoch 1/5, Train Loss: 4057.7416, Val Loss: 1553.4634\n",
            "Epoch 2/5, Train Loss: 716.0662, Val Loss: 199.1928\n",
            "Epoch 3/5, Train Loss: 77.5697, Val Loss: 17.6646\n",
            "Epoch 4/5, Train Loss: 10.0251, Val Loss: 6.4084\n",
            "Epoch 5/5, Train Loss: 6.3561, Val Loss: 5.6322\n",
            "Testing epochs=50\n",
            "Epoch 1/50, Train Loss: 3892.2973, Val Loss: 1455.6097\n",
            "Epoch 2/50, Train Loss: 661.5795, Val Loss: 180.2694\n",
            "Epoch 3/50, Train Loss: 73.0176, Val Loss: 18.7480\n",
            "Epoch 4/50, Train Loss: 12.1894, Val Loss: 8.6804\n",
            "Epoch 5/50, Train Loss: 8.6521, Val Loss: 8.1343\n",
            "Epoch 6/50, Train Loss: 8.0799, Val Loss: 7.6184\n",
            "Epoch 7/50, Train Loss: 7.6761, Val Loss: 7.2493\n",
            "Epoch 8/50, Train Loss: 7.3088, Val Loss: 7.5940\n",
            "Epoch 9/50, Train Loss: 7.0917, Val Loss: 6.3246\n",
            "Epoch 10/50, Train Loss: 6.3759, Val Loss: 5.6895\n",
            "Epoch 11/50, Train Loss: 5.8434, Val Loss: 5.5222\n",
            "Epoch 12/50, Train Loss: 5.3682, Val Loss: 5.0049\n",
            "Epoch 13/50, Train Loss: 4.9212, Val Loss: 4.4467\n",
            "Epoch 14/50, Train Loss: 4.0939, Val Loss: 3.5560\n",
            "Epoch 15/50, Train Loss: 3.5715, Val Loss: 3.1871\n",
            "Epoch 16/50, Train Loss: 2.7927, Val Loss: 2.1555\n",
            "Epoch 17/50, Train Loss: 2.0174, Val Loss: 1.6440\n",
            "Epoch 18/50, Train Loss: 1.5371, Val Loss: 0.9999\n",
            "Epoch 19/50, Train Loss: 0.9359, Val Loss: 0.7499\n",
            "Epoch 20/50, Train Loss: 0.5834, Val Loss: 0.4253\n",
            "Epoch 21/50, Train Loss: 0.4770, Val Loss: 0.3659\n",
            "Epoch 22/50, Train Loss: 0.2281, Val Loss: 0.1575\n",
            "Epoch 23/50, Train Loss: 0.1795, Val Loss: 0.1035\n",
            "Epoch 24/50, Train Loss: 0.2138, Val Loss: 0.0957\n",
            "Epoch 25/50, Train Loss: 0.1661, Val Loss: 0.0877\n",
            "Epoch 26/50, Train Loss: 0.1010, Val Loss: 0.0539\n",
            "Epoch 27/50, Train Loss: 0.1108, Val Loss: 0.1709\n",
            "Epoch 28/50, Train Loss: 0.3159, Val Loss: 0.0926\n",
            "Epoch 29/50, Train Loss: 0.1111, Val Loss: 0.1706\n",
            "Epoch 30/50, Train Loss: 0.0968, Val Loss: 0.0854\n",
            "Epoch 31/50, Train Loss: 0.0540, Val Loss: 0.0378\n",
            "Epoch 32/50, Train Loss: 0.0866, Val Loss: 0.0514\n",
            "Epoch 33/50, Train Loss: 0.0925, Val Loss: 0.0595\n",
            "Epoch 34/50, Train Loss: 0.1038, Val Loss: 0.1021\n",
            "Epoch 35/50, Train Loss: 0.0965, Val Loss: 0.0479\n",
            "Epoch 36/50, Train Loss: 0.0944, Val Loss: 0.0616\n",
            "Epoch 37/50, Train Loss: 0.0958, Val Loss: 0.1357\n",
            "Epoch 38/50, Train Loss: 0.0315, Val Loss: 0.0271\n",
            "Epoch 39/50, Train Loss: 0.0242, Val Loss: 0.0278\n",
            "Epoch 40/50, Train Loss: 0.0222, Val Loss: 0.0249\n",
            "Epoch 41/50, Train Loss: 0.0225, Val Loss: 0.0223\n",
            "Epoch 42/50, Train Loss: 0.0210, Val Loss: 0.0225\n",
            "Epoch 43/50, Train Loss: 0.0198, Val Loss: 0.0213\n",
            "Epoch 44/50, Train Loss: 0.0203, Val Loss: 0.0214\n",
            "Epoch 45/50, Train Loss: 0.0207, Val Loss: 0.0217\n",
            "Epoch 46/50, Train Loss: 0.0187, Val Loss: 0.0194\n",
            "Epoch 47/50, Train Loss: 0.0179, Val Loss: 0.0165\n",
            "Epoch 48/50, Train Loss: 0.0196, Val Loss: 0.0180\n",
            "Epoch 49/50, Train Loss: 0.0207, Val Loss: 0.0190\n",
            "Epoch 50/50, Train Loss: 0.0182, Val Loss: 0.0165\n",
            "Testing epochs=100\n",
            "Epoch 1/100, Train Loss: 3967.0869, Val Loss: 1550.1208\n",
            "Epoch 2/100, Train Loss: 734.4332, Val Loss: 217.1857\n",
            "Epoch 3/100, Train Loss: 97.1687, Val Loss: 34.2102\n",
            "Epoch 4/100, Train Loss: 26.8612, Val Loss: 21.2646\n",
            "Epoch 5/100, Train Loss: 21.3131, Val Loss: 19.6971\n",
            "Epoch 6/100, Train Loss: 19.8558, Val Loss: 18.3956\n",
            "Epoch 7/100, Train Loss: 18.7401, Val Loss: 16.9982\n",
            "Epoch 8/100, Train Loss: 17.1521, Val Loss: 15.7605\n",
            "Epoch 9/100, Train Loss: 15.6861, Val Loss: 14.2158\n",
            "Epoch 10/100, Train Loss: 14.1331, Val Loss: 13.2233\n",
            "Epoch 11/100, Train Loss: 13.7567, Val Loss: 11.5264\n",
            "Epoch 12/100, Train Loss: 11.1514, Val Loss: 9.5809\n",
            "Epoch 13/100, Train Loss: 9.2940, Val Loss: 8.1740\n",
            "Epoch 14/100, Train Loss: 8.0231, Val Loss: 6.8743\n",
            "Epoch 15/100, Train Loss: 6.2768, Val Loss: 5.0894\n",
            "Epoch 16/100, Train Loss: 4.5399, Val Loss: 3.5711\n",
            "Epoch 17/100, Train Loss: 3.2063, Val Loss: 2.6949\n",
            "Epoch 18/100, Train Loss: 2.4372, Val Loss: 1.9200\n",
            "Epoch 19/100, Train Loss: 1.6602, Val Loss: 1.2293\n",
            "Epoch 20/100, Train Loss: 1.0958, Val Loss: 0.7415\n",
            "Epoch 21/100, Train Loss: 0.7482, Val Loss: 0.5042\n",
            "Epoch 22/100, Train Loss: 0.7819, Val Loss: 0.3149\n",
            "Epoch 23/100, Train Loss: 0.4893, Val Loss: 0.3441\n",
            "Epoch 24/100, Train Loss: 0.2190, Val Loss: 0.1350\n",
            "Epoch 25/100, Train Loss: 0.1956, Val Loss: 0.1254\n",
            "Epoch 26/100, Train Loss: 0.1393, Val Loss: 0.0865\n",
            "Epoch 27/100, Train Loss: 0.0813, Val Loss: 0.0577\n",
            "Epoch 28/100, Train Loss: 0.1052, Val Loss: 0.1488\n",
            "Epoch 29/100, Train Loss: 0.2290, Val Loss: 0.2418\n",
            "Epoch 30/100, Train Loss: 0.1511, Val Loss: 0.0613\n",
            "Epoch 31/100, Train Loss: 0.0987, Val Loss: 0.0508\n",
            "Epoch 32/100, Train Loss: 0.0842, Val Loss: 0.1029\n",
            "Epoch 33/100, Train Loss: 0.0990, Val Loss: 0.3214\n",
            "Epoch 34/100, Train Loss: 0.0937, Val Loss: 0.1158\n",
            "Epoch 35/100, Train Loss: 0.2486, Val Loss: 0.5210\n",
            "Epoch 36/100, Train Loss: 0.1888, Val Loss: 0.0850\n",
            "Epoch 37/100, Train Loss: 0.0620, Val Loss: 0.0695\n",
            "Epoch 38/100, Train Loss: 0.0297, Val Loss: 0.0298\n",
            "Epoch 39/100, Train Loss: 0.0254, Val Loss: 0.0272\n",
            "Epoch 40/100, Train Loss: 0.0242, Val Loss: 0.0282\n",
            "Epoch 41/100, Train Loss: 0.0228, Val Loss: 0.0288\n",
            "Epoch 42/100, Train Loss: 0.0223, Val Loss: 0.0245\n",
            "Epoch 43/100, Train Loss: 0.0228, Val Loss: 0.0256\n",
            "Epoch 44/100, Train Loss: 0.0211, Val Loss: 0.0251\n",
            "Epoch 45/100, Train Loss: 0.0211, Val Loss: 0.0230\n",
            "Epoch 46/100, Train Loss: 0.0206, Val Loss: 0.0236\n",
            "Epoch 47/100, Train Loss: 0.0207, Val Loss: 0.0187\n",
            "Epoch 48/100, Train Loss: 0.0190, Val Loss: 0.0225\n",
            "Epoch 49/100, Train Loss: 0.0226, Val Loss: 0.0189\n",
            "Epoch 50/100, Train Loss: 0.0186, Val Loss: 0.0252\n",
            "Epoch 51/100, Train Loss: 0.0179, Val Loss: 0.0161\n",
            "Epoch 52/100, Train Loss: 0.0221, Val Loss: 0.0174\n",
            "Epoch 53/100, Train Loss: 0.0193, Val Loss: 0.0163\n",
            "Epoch 54/100, Train Loss: 0.0179, Val Loss: 0.0158\n",
            "Epoch 55/100, Train Loss: 0.0173, Val Loss: 0.0242\n",
            "Epoch 56/100, Train Loss: 0.0178, Val Loss: 0.0197\n",
            "Epoch 57/100, Train Loss: 0.0170, Val Loss: 0.0183\n",
            "Epoch 58/100, Train Loss: 0.0189, Val Loss: 0.0163\n",
            "Epoch 59/100, Train Loss: 0.0170, Val Loss: 0.0167\n",
            "Epoch 60/100, Train Loss: 0.0158, Val Loss: 0.0205\n",
            "Epoch 61/100, Train Loss: 0.0113, Val Loss: 0.0114\n",
            "Epoch 62/100, Train Loss: 0.0107, Val Loss: 0.0112\n",
            "Epoch 63/100, Train Loss: 0.0104, Val Loss: 0.0115\n",
            "Epoch 64/100, Train Loss: 0.0102, Val Loss: 0.0108\n",
            "Epoch 65/100, Train Loss: 0.0097, Val Loss: 0.0117\n",
            "Epoch 66/100, Train Loss: 0.0095, Val Loss: 0.0119\n",
            "Epoch 67/100, Train Loss: 0.0096, Val Loss: 0.0101\n",
            "Epoch 68/100, Train Loss: 0.0095, Val Loss: 0.0095\n",
            "Epoch 69/100, Train Loss: 0.0091, Val Loss: 0.0096\n",
            "Epoch 70/100, Train Loss: 0.0090, Val Loss: 0.0108\n",
            "Epoch 71/100, Train Loss: 0.0088, Val Loss: 0.0095\n",
            "Epoch 72/100, Train Loss: 0.0085, Val Loss: 0.0085\n",
            "Epoch 73/100, Train Loss: 0.0082, Val Loss: 0.0084\n",
            "Epoch 74/100, Train Loss: 0.0082, Val Loss: 0.0095\n",
            "Epoch 75/100, Train Loss: 0.0078, Val Loss: 0.0096\n",
            "Epoch 76/100, Train Loss: 0.0076, Val Loss: 0.0079\n",
            "Epoch 77/100, Train Loss: 0.0076, Val Loss: 0.0080\n",
            "Epoch 78/100, Train Loss: 0.0073, Val Loss: 0.0072\n",
            "Epoch 79/100, Train Loss: 0.0072, Val Loss: 0.0071\n",
            "Epoch 80/100, Train Loss: 0.0069, Val Loss: 0.0066\n",
            "Epoch 81/100, Train Loss: 0.0069, Val Loss: 0.0064\n",
            "Epoch 82/100, Train Loss: 0.0063, Val Loss: 0.0071\n",
            "Epoch 83/100, Train Loss: 0.0064, Val Loss: 0.0062\n",
            "Epoch 84/100, Train Loss: 0.0059, Val Loss: 0.0063\n",
            "Epoch 85/100, Train Loss: 0.0058, Val Loss: 0.0068\n",
            "Epoch 86/100, Train Loss: 0.0056, Val Loss: 0.0055\n",
            "Epoch 87/100, Train Loss: 0.0055, Val Loss: 0.0055\n",
            "Epoch 88/100, Train Loss: 0.0052, Val Loss: 0.0054\n",
            "Epoch 89/100, Train Loss: 0.0051, Val Loss: 0.0081\n",
            "Epoch 90/100, Train Loss: 0.0049, Val Loss: 0.0053\n",
            "Epoch 91/100, Train Loss: 0.0047, Val Loss: 0.0047\n",
            "Epoch 92/100, Train Loss: 0.0050, Val Loss: 0.0046\n",
            "Epoch 93/100, Train Loss: 0.0045, Val Loss: 0.0048\n",
            "Epoch 94/100, Train Loss: 0.0044, Val Loss: 0.0045\n",
            "Epoch 95/100, Train Loss: 0.0044, Val Loss: 0.0046\n",
            "Epoch 96/100, Train Loss: 0.0040, Val Loss: 0.0042\n",
            "Epoch 97/100, Train Loss: 0.0036, Val Loss: 0.0042\n",
            "Epoch 98/100, Train Loss: 0.0036, Val Loss: 0.0037\n",
            "Epoch 99/100, Train Loss: 0.0034, Val Loss: 0.0045\n",
            "Epoch 100/100, Train Loss: 0.0036, Val Loss: 0.0044\n",
            "Testing epochs=250\n",
            "Epoch 1/250, Train Loss: 3986.6170, Val Loss: 1540.8729\n",
            "Epoch 2/250, Train Loss: 698.3831, Val Loss: 192.9108\n",
            "Epoch 3/250, Train Loss: 77.9141, Val Loss: 24.6459\n",
            "Epoch 4/250, Train Loss: 12.4928, Val Loss: 8.9542\n",
            "Epoch 5/250, Train Loss: 8.7037, Val Loss: 8.0718\n",
            "Epoch 6/250, Train Loss: 7.9922, Val Loss: 7.3660\n",
            "Epoch 7/250, Train Loss: 7.5191, Val Loss: 6.8933\n",
            "Epoch 8/250, Train Loss: 7.1252, Val Loss: 6.5352\n",
            "Epoch 9/250, Train Loss: 6.8826, Val Loss: 6.2742\n",
            "Epoch 10/250, Train Loss: 6.2083, Val Loss: 5.6197\n",
            "Epoch 11/250, Train Loss: 5.8518, Val Loss: 5.1316\n",
            "Epoch 12/250, Train Loss: 5.1305, Val Loss: 4.5990\n",
            "Epoch 13/250, Train Loss: 4.6332, Val Loss: 4.6753\n",
            "Epoch 14/250, Train Loss: 4.2661, Val Loss: 3.4154\n",
            "Epoch 15/250, Train Loss: 3.1851, Val Loss: 2.5844\n",
            "Epoch 16/250, Train Loss: 2.3893, Val Loss: 1.8073\n",
            "Epoch 17/250, Train Loss: 1.6345, Val Loss: 1.2831\n",
            "Epoch 18/250, Train Loss: 1.2043, Val Loss: 0.9784\n",
            "Epoch 19/250, Train Loss: 0.7381, Val Loss: 0.5100\n",
            "Epoch 20/250, Train Loss: 0.5124, Val Loss: 0.5363\n",
            "Epoch 21/250, Train Loss: 0.4016, Val Loss: 0.3338\n",
            "Epoch 22/250, Train Loss: 0.3200, Val Loss: 0.2584\n",
            "Epoch 23/250, Train Loss: 0.1907, Val Loss: 0.1587\n",
            "Epoch 24/250, Train Loss: 0.1250, Val Loss: 0.1852\n",
            "Epoch 25/250, Train Loss: 0.2290, Val Loss: 0.1262\n",
            "Epoch 26/250, Train Loss: 0.1063, Val Loss: 0.0983\n",
            "Epoch 27/250, Train Loss: 0.1111, Val Loss: 0.0653\n",
            "Epoch 28/250, Train Loss: 0.1451, Val Loss: 0.1374\n",
            "Epoch 29/250, Train Loss: 0.1017, Val Loss: 0.1069\n",
            "Epoch 30/250, Train Loss: 0.1268, Val Loss: 0.1076\n",
            "Epoch 31/250, Train Loss: 0.1193, Val Loss: 0.2270\n",
            "Epoch 32/250, Train Loss: 0.1230, Val Loss: 0.0797\n",
            "Epoch 33/250, Train Loss: 0.0591, Val Loss: 0.0687\n",
            "Epoch 34/250, Train Loss: 0.0264, Val Loss: 0.0281\n",
            "Epoch 35/250, Train Loss: 0.0228, Val Loss: 0.0296\n",
            "Epoch 36/250, Train Loss: 0.0219, Val Loss: 0.0232\n",
            "Epoch 37/250, Train Loss: 0.0210, Val Loss: 0.0267\n",
            "Epoch 38/250, Train Loss: 0.0199, Val Loss: 0.0235\n",
            "Epoch 39/250, Train Loss: 0.0201, Val Loss: 0.0246\n",
            "Epoch 40/250, Train Loss: 0.0209, Val Loss: 0.0200\n",
            "Epoch 41/250, Train Loss: 0.0189, Val Loss: 0.0198\n",
            "Epoch 42/250, Train Loss: 0.0196, Val Loss: 0.0189\n",
            "Epoch 43/250, Train Loss: 0.0193, Val Loss: 0.0208\n",
            "Epoch 44/250, Train Loss: 0.0180, Val Loss: 0.0180\n",
            "Epoch 45/250, Train Loss: 0.0173, Val Loss: 0.0179\n",
            "Epoch 46/250, Train Loss: 0.0180, Val Loss: 0.0163\n",
            "Epoch 47/250, Train Loss: 0.0192, Val Loss: 0.0167\n",
            "Epoch 48/250, Train Loss: 0.0183, Val Loss: 0.0345\n",
            "Epoch 49/250, Train Loss: 0.0179, Val Loss: 0.0187\n",
            "Epoch 50/250, Train Loss: 0.0170, Val Loss: 0.0228\n",
            "Epoch 51/250, Train Loss: 0.0178, Val Loss: 0.0187\n",
            "Epoch 52/250, Train Loss: 0.0164, Val Loss: 0.0184\n",
            "Epoch 53/250, Train Loss: 0.0141, Val Loss: 0.0136\n",
            "Epoch 54/250, Train Loss: 0.0129, Val Loss: 0.0145\n",
            "Epoch 55/250, Train Loss: 0.0123, Val Loss: 0.0136\n",
            "Epoch 56/250, Train Loss: 0.0119, Val Loss: 0.0138\n",
            "Epoch 57/250, Train Loss: 0.0122, Val Loss: 0.0155\n",
            "Epoch 58/250, Train Loss: 0.0122, Val Loss: 0.0135\n",
            "Epoch 59/250, Train Loss: 0.0120, Val Loss: 0.0135\n",
            "Epoch 60/250, Train Loss: 0.0119, Val Loss: 0.0147\n",
            "Epoch 61/250, Train Loss: 0.0118, Val Loss: 0.0130\n",
            "Epoch 62/250, Train Loss: 0.0119, Val Loss: 0.0130\n",
            "Epoch 63/250, Train Loss: 0.0117, Val Loss: 0.0127\n",
            "Epoch 64/250, Train Loss: 0.0114, Val Loss: 0.0122\n",
            "Epoch 65/250, Train Loss: 0.0117, Val Loss: 0.0123\n",
            "Epoch 66/250, Train Loss: 0.0114, Val Loss: 0.0134\n",
            "Epoch 67/250, Train Loss: 0.0111, Val Loss: 0.0127\n",
            "Epoch 68/250, Train Loss: 0.0110, Val Loss: 0.0125\n",
            "Epoch 69/250, Train Loss: 0.0108, Val Loss: 0.0115\n",
            "Epoch 70/250, Train Loss: 0.0111, Val Loss: 0.0119\n",
            "Epoch 71/250, Train Loss: 0.0107, Val Loss: 0.0111\n",
            "Epoch 72/250, Train Loss: 0.0105, Val Loss: 0.0119\n",
            "Epoch 73/250, Train Loss: 0.0106, Val Loss: 0.0110\n",
            "Epoch 74/250, Train Loss: 0.0104, Val Loss: 0.0118\n",
            "Epoch 75/250, Train Loss: 0.0101, Val Loss: 0.0110\n",
            "Epoch 76/250, Train Loss: 0.0101, Val Loss: 0.0113\n",
            "Epoch 77/250, Train Loss: 0.0098, Val Loss: 0.0105\n",
            "Epoch 78/250, Train Loss: 0.0093, Val Loss: 0.0109\n",
            "Epoch 79/250, Train Loss: 0.0094, Val Loss: 0.0107\n",
            "Epoch 80/250, Train Loss: 0.0092, Val Loss: 0.0101\n",
            "Epoch 81/250, Train Loss: 0.0091, Val Loss: 0.0116\n",
            "Epoch 82/250, Train Loss: 0.0090, Val Loss: 0.0093\n",
            "Epoch 83/250, Train Loss: 0.0087, Val Loss: 0.0096\n",
            "Epoch 84/250, Train Loss: 0.0087, Val Loss: 0.0087\n",
            "Epoch 85/250, Train Loss: 0.0085, Val Loss: 0.0087\n",
            "Epoch 86/250, Train Loss: 0.0080, Val Loss: 0.0079\n",
            "Epoch 87/250, Train Loss: 0.0078, Val Loss: 0.0083\n",
            "Epoch 88/250, Train Loss: 0.0077, Val Loss: 0.0079\n",
            "Epoch 89/250, Train Loss: 0.0075, Val Loss: 0.0094\n",
            "Epoch 90/250, Train Loss: 0.0073, Val Loss: 0.0084\n",
            "Epoch 91/250, Train Loss: 0.0076, Val Loss: 0.0075\n",
            "Epoch 92/250, Train Loss: 0.0073, Val Loss: 0.0074\n",
            "Epoch 93/250, Train Loss: 0.0068, Val Loss: 0.0067\n",
            "Epoch 94/250, Train Loss: 0.0066, Val Loss: 0.0064\n",
            "Epoch 95/250, Train Loss: 0.0065, Val Loss: 0.0075\n",
            "Epoch 96/250, Train Loss: 0.0062, Val Loss: 0.0063\n",
            "Epoch 97/250, Train Loss: 0.0061, Val Loss: 0.0058\n",
            "Epoch 98/250, Train Loss: 0.0061, Val Loss: 0.0057\n",
            "Epoch 99/250, Train Loss: 0.0059, Val Loss: 0.0054\n",
            "Epoch 100/250, Train Loss: 0.0056, Val Loss: 0.0060\n",
            "Epoch 101/250, Train Loss: 0.0053, Val Loss: 0.0059\n",
            "Epoch 102/250, Train Loss: 0.0057, Val Loss: 0.0049\n",
            "Epoch 103/250, Train Loss: 0.0049, Val Loss: 0.0060\n",
            "Epoch 104/250, Train Loss: 0.0053, Val Loss: 0.0047\n",
            "Epoch 105/250, Train Loss: 0.0048, Val Loss: 0.0050\n",
            "Epoch 106/250, Train Loss: 0.0044, Val Loss: 0.0076\n",
            "Epoch 107/250, Train Loss: 0.0047, Val Loss: 0.0043\n",
            "Epoch 108/250, Train Loss: 0.0047, Val Loss: 0.0046\n",
            "Epoch 109/250, Train Loss: 0.0043, Val Loss: 0.0043\n",
            "Epoch 110/250, Train Loss: 0.0041, Val Loss: 0.0040\n",
            "Epoch 111/250, Train Loss: 0.0040, Val Loss: 0.0039\n",
            "Epoch 112/250, Train Loss: 0.0040, Val Loss: 0.0038\n",
            "Epoch 113/250, Train Loss: 0.0040, Val Loss: 0.0035\n",
            "Epoch 114/250, Train Loss: 0.0037, Val Loss: 0.0036\n",
            "Epoch 115/250, Train Loss: 0.0033, Val Loss: 0.0039\n",
            "Epoch 116/250, Train Loss: 0.0034, Val Loss: 0.0032\n",
            "Epoch 117/250, Train Loss: 0.0032, Val Loss: 0.0032\n",
            "Epoch 118/250, Train Loss: 0.0035, Val Loss: 0.0038\n",
            "Epoch 119/250, Train Loss: 0.0031, Val Loss: 0.0039\n",
            "Epoch 120/250, Train Loss: 0.0030, Val Loss: 0.0030\n",
            "Epoch 121/250, Train Loss: 0.0028, Val Loss: 0.0027\n",
            "Epoch 122/250, Train Loss: 0.0028, Val Loss: 0.0031\n",
            "Epoch 123/250, Train Loss: 0.0026, Val Loss: 0.0032\n",
            "Epoch 124/250, Train Loss: 0.0027, Val Loss: 0.0032\n",
            "Epoch 125/250, Train Loss: 0.0024, Val Loss: 0.0028\n",
            "Epoch 126/250, Train Loss: 0.0023, Val Loss: 0.0027\n",
            "Epoch 127/250, Train Loss: 0.0026, Val Loss: 0.0026\n",
            "Epoch 128/250, Train Loss: 0.0025, Val Loss: 0.0024\n",
            "Epoch 129/250, Train Loss: 0.0022, Val Loss: 0.0023\n",
            "Epoch 130/250, Train Loss: 0.0028, Val Loss: 0.0032\n",
            "Epoch 131/250, Train Loss: 0.0023, Val Loss: 0.0038\n",
            "Epoch 132/250, Train Loss: 0.0021, Val Loss: 0.0022\n",
            "Epoch 133/250, Train Loss: 0.0021, Val Loss: 0.0020\n",
            "Epoch 134/250, Train Loss: 0.0020, Val Loss: 0.0026\n",
            "Epoch 135/250, Train Loss: 0.0018, Val Loss: 0.0026\n",
            "Epoch 136/250, Train Loss: 0.0020, Val Loss: 0.0022\n",
            "Epoch 137/250, Train Loss: 0.0019, Val Loss: 0.0021\n",
            "Epoch 138/250, Train Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch 139/250, Train Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch 140/250, Train Loss: 0.0018, Val Loss: 0.0020\n",
            "Epoch 141/250, Train Loss: 0.0017, Val Loss: 0.0020\n",
            "Epoch 142/250, Train Loss: 0.0017, Val Loss: 0.0020\n",
            "Epoch 143/250, Train Loss: 0.0016, Val Loss: 0.0024\n",
            "Epoch 144/250, Train Loss: 0.0018, Val Loss: 0.0018\n",
            "Epoch 145/250, Train Loss: 0.0017, Val Loss: 0.0034\n",
            "Epoch 146/250, Train Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch 147/250, Train Loss: 0.0015, Val Loss: 0.0016\n",
            "Epoch 148/250, Train Loss: 0.0017, Val Loss: 0.0019\n",
            "Epoch 149/250, Train Loss: 0.0016, Val Loss: 0.0023\n",
            "Epoch 150/250, Train Loss: 0.0017, Val Loss: 0.0023\n",
            "Epoch 151/250, Train Loss: 0.0016, Val Loss: 0.0019\n",
            "Epoch 152/250, Train Loss: 0.0015, Val Loss: 0.0017\n",
            "Epoch 153/250, Train Loss: 0.0015, Val Loss: 0.0020\n",
            "Epoch 154/250, Train Loss: 0.0012, Val Loss: 0.0015\n",
            "Epoch 155/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 156/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 157/250, Train Loss: 0.0012, Val Loss: 0.0015\n",
            "Epoch 158/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 159/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 160/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 161/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 162/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 163/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 164/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 165/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 166/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 167/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 168/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 169/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 170/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 171/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 172/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 173/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 174/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 175/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 176/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 177/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 178/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 179/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 180/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 181/250, Train Loss: 0.0011, Val Loss: 0.0015\n",
            "Epoch 182/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 183/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 184/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 185/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 186/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 187/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 188/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 189/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 190/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 191/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 192/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 193/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 194/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 195/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 196/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 197/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 198/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 199/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 200/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 201/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 202/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 203/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 204/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 205/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 206/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 207/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 208/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 209/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 210/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 211/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 212/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 213/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 214/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 215/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 216/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 217/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 218/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 219/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 220/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 221/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 222/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 223/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 224/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 225/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 226/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 227/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 228/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 229/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 230/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 231/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 232/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 233/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 234/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 235/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 236/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 237/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 238/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 239/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 240/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 241/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 242/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 243/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 244/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 245/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 246/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 247/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 248/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 249/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch 250/250, Train Loss: 0.0011, Val Loss: 0.0014\n",
            "Testing epochs=350\n",
            "Epoch 1/350, Train Loss: 3910.5373, Val Loss: 1481.0893\n",
            "Epoch 2/350, Train Loss: 672.0811, Val Loss: 184.4463\n",
            "Epoch 3/350, Train Loss: 74.4532, Val Loss: 19.1622\n",
            "Epoch 4/350, Train Loss: 12.2796, Val Loss: 8.5328\n",
            "Epoch 5/350, Train Loss: 9.4017, Val Loss: 8.1365\n",
            "Epoch 6/350, Train Loss: 7.9527, Val Loss: 7.3670\n",
            "Epoch 7/350, Train Loss: 7.6300, Val Loss: 7.0255\n",
            "Epoch 8/350, Train Loss: 7.2305, Val Loss: 6.5814\n",
            "Epoch 9/350, Train Loss: 6.6594, Val Loss: 6.0434\n",
            "Epoch 10/350, Train Loss: 6.2770, Val Loss: 5.5970\n",
            "Epoch 11/350, Train Loss: 5.6736, Val Loss: 5.1598\n",
            "Epoch 12/350, Train Loss: 5.1644, Val Loss: 4.5503\n",
            "Epoch 13/350, Train Loss: 4.5926, Val Loss: 4.2743\n",
            "Epoch 14/350, Train Loss: 4.1392, Val Loss: 3.7952\n",
            "Epoch 15/350, Train Loss: 3.4520, Val Loss: 2.7126\n",
            "Epoch 16/350, Train Loss: 2.7154, Val Loss: 2.1225\n",
            "Epoch 17/350, Train Loss: 1.9355, Val Loss: 1.4900\n",
            "Epoch 18/350, Train Loss: 1.3697, Val Loss: 1.1145\n",
            "Epoch 19/350, Train Loss: 0.9169, Val Loss: 0.6483\n",
            "Epoch 20/350, Train Loss: 0.6621, Val Loss: 0.4409\n",
            "Epoch 21/350, Train Loss: 0.3742, Val Loss: 0.3196\n",
            "Epoch 22/350, Train Loss: 0.2977, Val Loss: 0.2302\n",
            "Epoch 23/350, Train Loss: 0.2047, Val Loss: 0.1518\n",
            "Epoch 24/350, Train Loss: 0.1816, Val Loss: 0.2686\n",
            "Epoch 25/350, Train Loss: 0.1851, Val Loss: 0.0808\n",
            "Epoch 26/350, Train Loss: 0.1023, Val Loss: 0.0994\n",
            "Epoch 27/350, Train Loss: 0.1150, Val Loss: 0.1372\n",
            "Epoch 28/350, Train Loss: 0.2168, Val Loss: 0.1189\n",
            "Epoch 29/350, Train Loss: 0.1216, Val Loss: 0.2769\n",
            "Epoch 30/350, Train Loss: 0.1401, Val Loss: 0.0966\n",
            "Epoch 31/350, Train Loss: 0.1089, Val Loss: 0.0884\n",
            "Epoch 32/350, Train Loss: 0.0447, Val Loss: 0.0395\n",
            "Epoch 33/350, Train Loss: 0.0356, Val Loss: 0.0386\n",
            "Epoch 34/350, Train Loss: 0.0326, Val Loss: 0.0334\n",
            "Epoch 35/350, Train Loss: 0.0314, Val Loss: 0.0328\n",
            "Epoch 36/350, Train Loss: 0.0301, Val Loss: 0.0313\n",
            "Epoch 37/350, Train Loss: 0.0297, Val Loss: 0.0321\n",
            "Epoch 38/350, Train Loss: 0.0278, Val Loss: 0.0286\n",
            "Epoch 39/350, Train Loss: 0.0280, Val Loss: 0.0294\n",
            "Epoch 40/350, Train Loss: 0.0278, Val Loss: 0.0384\n",
            "Epoch 41/350, Train Loss: 0.0289, Val Loss: 0.0280\n",
            "Epoch 42/350, Train Loss: 0.0255, Val Loss: 0.0258\n",
            "Epoch 43/350, Train Loss: 0.0278, Val Loss: 0.0242\n",
            "Epoch 44/350, Train Loss: 0.0289, Val Loss: 0.0373\n",
            "Epoch 45/350, Train Loss: 0.0258, Val Loss: 0.0258\n",
            "Epoch 46/350, Train Loss: 0.0265, Val Loss: 0.0257\n",
            "Epoch 47/350, Train Loss: 0.0239, Val Loss: 0.0237\n",
            "Epoch 48/350, Train Loss: 0.0240, Val Loss: 0.0277\n",
            "Epoch 49/350, Train Loss: 0.0223, Val Loss: 0.0223\n",
            "Epoch 50/350, Train Loss: 0.0242, Val Loss: 0.0337\n",
            "Epoch 51/350, Train Loss: 0.0222, Val Loss: 0.0190\n",
            "Epoch 52/350, Train Loss: 0.0223, Val Loss: 0.0192\n",
            "Epoch 53/350, Train Loss: 0.0302, Val Loss: 0.0223\n",
            "Epoch 54/350, Train Loss: 0.0236, Val Loss: 0.0294\n",
            "Epoch 55/350, Train Loss: 0.0218, Val Loss: 0.0170\n",
            "Epoch 56/350, Train Loss: 0.0215, Val Loss: 0.0377\n",
            "Epoch 57/350, Train Loss: 0.0254, Val Loss: 0.0249\n",
            "Epoch 58/350, Train Loss: 0.0222, Val Loss: 0.0182\n",
            "Epoch 59/350, Train Loss: 0.0209, Val Loss: 0.0213\n",
            "Epoch 60/350, Train Loss: 0.0211, Val Loss: 0.0206\n",
            "Epoch 61/350, Train Loss: 0.0210, Val Loss: 0.0205\n",
            "Epoch 62/350, Train Loss: 0.0128, Val Loss: 0.0134\n",
            "Epoch 63/350, Train Loss: 0.0123, Val Loss: 0.0136\n",
            "Epoch 64/350, Train Loss: 0.0121, Val Loss: 0.0130\n",
            "Epoch 65/350, Train Loss: 0.0118, Val Loss: 0.0133\n",
            "Epoch 66/350, Train Loss: 0.0117, Val Loss: 0.0141\n",
            "Epoch 67/350, Train Loss: 0.0114, Val Loss: 0.0124\n",
            "Epoch 68/350, Train Loss: 0.0115, Val Loss: 0.0130\n",
            "Epoch 69/350, Train Loss: 0.0112, Val Loss: 0.0120\n",
            "Epoch 70/350, Train Loss: 0.0111, Val Loss: 0.0127\n",
            "Epoch 71/350, Train Loss: 0.0105, Val Loss: 0.0121\n",
            "Epoch 72/350, Train Loss: 0.0102, Val Loss: 0.0115\n",
            "Epoch 73/350, Train Loss: 0.0102, Val Loss: 0.0107\n",
            "Epoch 74/350, Train Loss: 0.0101, Val Loss: 0.0120\n",
            "Epoch 75/350, Train Loss: 0.0100, Val Loss: 0.0106\n",
            "Epoch 76/350, Train Loss: 0.0095, Val Loss: 0.0102\n",
            "Epoch 77/350, Train Loss: 0.0093, Val Loss: 0.0105\n",
            "Epoch 78/350, Train Loss: 0.0094, Val Loss: 0.0101\n",
            "Epoch 79/350, Train Loss: 0.0087, Val Loss: 0.0094\n",
            "Epoch 80/350, Train Loss: 0.0086, Val Loss: 0.0098\n",
            "Epoch 81/350, Train Loss: 0.0083, Val Loss: 0.0092\n",
            "Epoch 82/350, Train Loss: 0.0081, Val Loss: 0.0098\n",
            "Epoch 83/350, Train Loss: 0.0080, Val Loss: 0.0085\n",
            "Epoch 84/350, Train Loss: 0.0075, Val Loss: 0.0086\n",
            "Epoch 85/350, Train Loss: 0.0076, Val Loss: 0.0085\n",
            "Epoch 86/350, Train Loss: 0.0072, Val Loss: 0.0078\n",
            "Epoch 87/350, Train Loss: 0.0076, Val Loss: 0.0076\n",
            "Epoch 88/350, Train Loss: 0.0073, Val Loss: 0.0081\n",
            "Epoch 89/350, Train Loss: 0.0072, Val Loss: 0.0082\n",
            "Epoch 90/350, Train Loss: 0.0066, Val Loss: 0.0075\n",
            "Epoch 91/350, Train Loss: 0.0066, Val Loss: 0.0075\n",
            "Epoch 92/350, Train Loss: 0.0061, Val Loss: 0.0071\n",
            "Epoch 93/350, Train Loss: 0.0061, Val Loss: 0.0067\n",
            "Epoch 94/350, Train Loss: 0.0058, Val Loss: 0.0068\n",
            "Epoch 95/350, Train Loss: 0.0059, Val Loss: 0.0066\n",
            "Epoch 96/350, Train Loss: 0.0058, Val Loss: 0.0063\n",
            "Epoch 97/350, Train Loss: 0.0055, Val Loss: 0.0062\n",
            "Epoch 98/350, Train Loss: 0.0053, Val Loss: 0.0062\n",
            "Epoch 99/350, Train Loss: 0.0054, Val Loss: 0.0066\n",
            "Epoch 100/350, Train Loss: 0.0053, Val Loss: 0.0062\n",
            "Epoch 101/350, Train Loss: 0.0051, Val Loss: 0.0066\n",
            "Epoch 102/350, Train Loss: 0.0048, Val Loss: 0.0067\n",
            "Epoch 103/350, Train Loss: 0.0050, Val Loss: 0.0055\n",
            "Epoch 104/350, Train Loss: 0.0048, Val Loss: 0.0057\n",
            "Epoch 105/350, Train Loss: 0.0045, Val Loss: 0.0055\n",
            "Epoch 106/350, Train Loss: 0.0045, Val Loss: 0.0054\n",
            "Epoch 107/350, Train Loss: 0.0046, Val Loss: 0.0054\n",
            "Epoch 108/350, Train Loss: 0.0045, Val Loss: 0.0053\n",
            "Epoch 109/350, Train Loss: 0.0042, Val Loss: 0.0053\n",
            "Epoch 110/350, Train Loss: 0.0042, Val Loss: 0.0051\n",
            "Epoch 111/350, Train Loss: 0.0041, Val Loss: 0.0060\n",
            "Epoch 112/350, Train Loss: 0.0040, Val Loss: 0.0059\n",
            "Epoch 113/350, Train Loss: 0.0040, Val Loss: 0.0051\n",
            "Epoch 114/350, Train Loss: 0.0040, Val Loss: 0.0050\n",
            "Epoch 115/350, Train Loss: 0.0042, Val Loss: 0.0049\n",
            "Epoch 116/350, Train Loss: 0.0038, Val Loss: 0.0046\n",
            "Epoch 117/350, Train Loss: 0.0038, Val Loss: 0.0047\n",
            "Epoch 118/350, Train Loss: 0.0037, Val Loss: 0.0052\n",
            "Epoch 119/350, Train Loss: 0.0041, Val Loss: 0.0050\n",
            "Epoch 120/350, Train Loss: 0.0037, Val Loss: 0.0047\n",
            "Epoch 121/350, Train Loss: 0.0037, Val Loss: 0.0048\n",
            "Epoch 122/350, Train Loss: 0.0036, Val Loss: 0.0044\n",
            "Epoch 123/350, Train Loss: 0.0035, Val Loss: 0.0048\n",
            "Epoch 124/350, Train Loss: 0.0035, Val Loss: 0.0047\n",
            "Epoch 125/350, Train Loss: 0.0037, Val Loss: 0.0044\n",
            "Epoch 126/350, Train Loss: 0.0036, Val Loss: 0.0049\n",
            "Epoch 127/350, Train Loss: 0.0034, Val Loss: 0.0044\n",
            "Epoch 128/350, Train Loss: 0.0035, Val Loss: 0.0046\n",
            "Epoch 129/350, Train Loss: 0.0033, Val Loss: 0.0042\n",
            "Epoch 130/350, Train Loss: 0.0035, Val Loss: 0.0042\n",
            "Epoch 131/350, Train Loss: 0.0035, Val Loss: 0.0044\n",
            "Epoch 132/350, Train Loss: 0.0035, Val Loss: 0.0042\n",
            "Epoch 133/350, Train Loss: 0.0033, Val Loss: 0.0048\n",
            "Epoch 134/350, Train Loss: 0.0034, Val Loss: 0.0042\n",
            "Epoch 135/350, Train Loss: 0.0032, Val Loss: 0.0049\n",
            "Epoch 136/350, Train Loss: 0.0035, Val Loss: 0.0042\n",
            "Epoch 137/350, Train Loss: 0.0033, Val Loss: 0.0042\n",
            "Epoch 138/350, Train Loss: 0.0034, Val Loss: 0.0041\n",
            "Epoch 139/350, Train Loss: 0.0032, Val Loss: 0.0043\n",
            "Epoch 140/350, Train Loss: 0.0033, Val Loss: 0.0044\n",
            "Epoch 141/350, Train Loss: 0.0032, Val Loss: 0.0040\n",
            "Epoch 142/350, Train Loss: 0.0031, Val Loss: 0.0043\n",
            "Epoch 143/350, Train Loss: 0.0032, Val Loss: 0.0040\n",
            "Epoch 144/350, Train Loss: 0.0031, Val Loss: 0.0039\n",
            "Epoch 145/350, Train Loss: 0.0032, Val Loss: 0.0040\n",
            "Epoch 146/350, Train Loss: 0.0030, Val Loss: 0.0041\n",
            "Epoch 147/350, Train Loss: 0.0032, Val Loss: 0.0040\n",
            "Epoch 148/350, Train Loss: 0.0030, Val Loss: 0.0041\n",
            "Epoch 149/350, Train Loss: 0.0031, Val Loss: 0.0037\n",
            "Epoch 150/350, Train Loss: 0.0032, Val Loss: 0.0037\n",
            "Epoch 151/350, Train Loss: 0.0030, Val Loss: 0.0038\n",
            "Epoch 152/350, Train Loss: 0.0030, Val Loss: 0.0039\n",
            "Epoch 153/350, Train Loss: 0.0030, Val Loss: 0.0039\n",
            "Epoch 154/350, Train Loss: 0.0029, Val Loss: 0.0037\n",
            "Epoch 155/350, Train Loss: 0.0036, Val Loss: 0.0040\n",
            "Epoch 156/350, Train Loss: 0.0029, Val Loss: 0.0037\n",
            "Epoch 157/350, Train Loss: 0.0026, Val Loss: 0.0035\n",
            "Epoch 158/350, Train Loss: 0.0026, Val Loss: 0.0035\n",
            "Epoch 159/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 160/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 161/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 162/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 163/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 164/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 165/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 166/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 167/350, Train Loss: 0.0025, Val Loss: 0.0035\n",
            "Epoch 168/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 169/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 170/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 171/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 172/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 173/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 174/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 175/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 176/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 177/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 178/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 179/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 180/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 181/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 182/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 183/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 184/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 185/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 186/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 187/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 188/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 189/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 190/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 191/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 192/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 193/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 194/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 195/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 196/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 197/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 198/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 199/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 200/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 201/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 202/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 203/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 204/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 205/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 206/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 207/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 208/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 209/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 210/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 211/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 212/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 213/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 214/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 215/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 216/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 217/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 218/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 219/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 220/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 221/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 222/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 223/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 224/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 225/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 226/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 227/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 228/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 229/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 230/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 231/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 232/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 233/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 234/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 235/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 236/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 237/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 238/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 239/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 240/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 241/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 242/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 243/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 244/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 245/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 246/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 247/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 248/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 249/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 250/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 251/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 252/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 253/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 254/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 255/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 256/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 257/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 258/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 259/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 260/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 261/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 262/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 263/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 264/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 265/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 266/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 267/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 268/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 269/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 270/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 271/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 272/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 273/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 274/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 275/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 276/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 277/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 278/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 279/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 280/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 281/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 282/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 283/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 284/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 285/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 286/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 287/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 288/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 289/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 290/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 291/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 292/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 293/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 294/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 295/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 296/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 297/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 298/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 299/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 300/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 301/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 302/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 303/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 304/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 305/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 306/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 307/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 308/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 309/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 310/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 311/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 312/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 313/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 314/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 315/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 316/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 317/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 318/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 319/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 320/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 321/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 322/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 323/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 324/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 325/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 326/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 327/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 328/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 329/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 330/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 331/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 332/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 333/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 334/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 335/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 336/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 337/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 338/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 339/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 340/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 341/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 342/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 343/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 344/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 345/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 346/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 347/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 348/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 349/350, Train Loss: 0.0025, Val Loss: 0.0034\n",
            "Epoch 350/350, Train Loss: 0.0025, Val Loss: 0.0034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "hidden_size_df = pd.DataFrame(hidden_size_results)\n",
        "hidden_size_df.to_csv(\"hidden_size_experiment.csv\", index=False)\n",
        "\n",
        "pooling_df = pd.DataFrame(pooling_results)\n",
        "pooling_df.to_csv(\"pooling_experiment.csv\", index=False)\n",
        "\n",
        "optimizer_df = pd.DataFrame(optimizer_results)\n",
        "optimizer_df.to_csv(\"optimizer_experiment.csv\", index=False)\n",
        "\n",
        "epoch_df = pd.DataFrame(epoch_results)\n",
        "epoch_df.to_csv(\"epoch_experiment.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "5YlVnIxE4YY9"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
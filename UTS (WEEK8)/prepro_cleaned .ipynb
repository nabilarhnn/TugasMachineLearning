{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI48O1tMwLO6",
        "outputId": "5e61e2f8-ac61-480e-ef21-c10da12dcc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape after dropping duplicates: (515130, 91)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-abb393ea8552>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['x20_log'] = np.log1p(data['x20'])  # Transform target to reduce skewness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skewness before removing high-skewed features:\n",
            "x59    4.510444\n",
            "x25    4.171404\n",
            "x17    3.450913\n",
            "x22    3.283011\n",
            "x24    3.139351\n",
            "x18    3.102336\n",
            "x70    3.081634\n",
            "x15    2.926859\n",
            "x21    2.669088\n",
            "x19    2.248271\n",
            "x16    2.222596\n",
            "x82    2.187223\n",
            "x27    2.136054\n",
            "x14    2.053276\n",
            "x23    1.997108\n",
            "x84    1.690973\n",
            "x58    1.673140\n",
            "x57    1.600399\n",
            "x49    1.453871\n",
            "x38    1.446828\n",
            "x60    1.318823\n",
            "x34    1.318001\n",
            "x37    1.208768\n",
            "x53    1.015985\n",
            "x5     0.974358\n",
            "x7     0.846846\n",
            "x64    0.832200\n",
            "x39    0.519905\n",
            "x68    0.326747\n",
            "x47    0.156928\n",
            "x85    0.106440\n",
            "x65    0.089468\n",
            "x6     0.068126\n",
            "x4    -0.153239\n",
            "x12   -0.193047\n",
            "x10   -0.256650\n",
            "x32   -0.516374\n",
            "x76   -0.661759\n",
            "x51   -0.853213\n",
            "x3    -0.860269\n",
            "x2    -0.895416\n",
            "x81   -1.002561\n",
            "x48   -1.100670\n",
            "x83   -1.365475\n",
            "x77   -1.600167\n",
            "x72   -2.069324\n",
            "x56   -2.250034\n",
            "x40   -2.454756\n",
            "x44   -3.273497\n",
            "x80   -4.339337\n",
            "dtype: float64\n",
            "Removing features with high skewness: ['x59', 'x25', 'x17', 'x22', 'x24', 'x18', 'x70', 'x15', 'x21', 'x19', 'x16', 'x82', 'x27', 'x14', 'x23', 'x84', 'x58', 'x57', 'x49', 'x38', 'x60', 'x34', 'x37', 'x53', 'x81', 'x48', 'x83', 'x77', 'x72', 'x56', 'x40', 'x44', 'x80']\n",
            "Processed dataset saved as: /content/RegresiUTSTelkom_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/RegresiUTSTelkom.csv')  # Replace with your dataset path\n",
        "\n",
        "# # Rename columns to x1, x2, ..., x91\n",
        "column_names = [f'x{i}' for i in range(1, data.shape[1] + 1)]\n",
        "data.columns = column_names\n",
        "\n",
        "# Step 2: Drop duplicate rows\n",
        "data = data.drop_duplicates()\n",
        "print(f\"Dataset shape after dropping duplicates: {data.shape}\")\n",
        "\n",
        "# Step 3: Transform target (log-transform x20)\n",
        "data['x20_log'] = np.log1p(data['x20'])  # Transform target to reduce skewness\n",
        "target = data['x20_log']\n",
        "data = data.drop(columns=['x20', 'x20_log'])  # Drop original and transformed target for feature selection\n",
        "\n",
        "# Step 4: Select features based on correlation with x20_log\n",
        "correlation_threshold = 0.1\n",
        "correlation_with_target = data.corrwith(target).abs()  # Compute absolute correlation\n",
        "selected_features = correlation_with_target[correlation_with_target > correlation_threshold].index\n",
        "data_selected = data[selected_features]\n",
        "\n",
        "# Step 5: Apply Variance Threshold to selected features\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "variance_threshold = 0.1\n",
        "selector = VarianceThreshold(threshold=variance_threshold)\n",
        "data_high_variance = selector.fit_transform(data_selected)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "data_final = pd.DataFrame(data_high_variance, columns=[col for col, keep in zip(data_selected.columns, selector.get_support()) if keep])\n",
        "\n",
        "# Step 6: Calculate skewness and remove features with high skewness\n",
        "skewness = data_final.skew().sort_values(ascending=False)\n",
        "print(\"Skewness before removing high-skewed features:\")\n",
        "print(skewness)\n",
        "\n",
        "# Remove features with skewness > 1 or skewness < -1\n",
        "high_skewed_features = skewness[(skewness > 1) | (skewness < -1)].index\n",
        "print(f\"Removing features with high skewness: {list(high_skewed_features)}\")\n",
        "data_final = data_final.drop(columns=high_skewed_features)\n",
        "\n",
        "# Step 7: Save the reduced dataset\n",
        "processed_file_path = \"/content/RegresiUTSTelkom_cleaned.csv\"\n",
        "data_final.to_csv(processed_file_path, index=False)\n",
        "\n",
        "print(\"Processed dataset saved as:\", processed_file_path)"
      ]
    }
  ]
}